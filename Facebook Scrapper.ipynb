{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap Page Details to JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# RAPID API credentials\n",
    "url = \"https://facebook-pages-scraper2.p.rapidapi.com/get_facebook_pages_details\"\n",
    "headers = {\n",
    "    \"x-rapidapi-host\": \"facebook-pages-scraper2.p.rapidapi.com\",\n",
    "    \"x-rapidapi-key\": \"YOUR_API_KEY_HERE\" # Insert API Key\n",
    "}\n",
    "\n",
    "# Target Facebook Page link\n",
    "params = {\"link\": \"https://www.facebook.com/YourPageName\"}  # Insert The Facebook Page \n",
    "\n",
    "# API Request\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "# Save JSON Response to a File\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Full JSON response\n",
    "    \n",
    "    # Save to a file\n",
    "    with open('facebook_page_details.json', 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(\"JSON saved successfully to 'facebook_page_details.json'\")\n",
    "else:\n",
    "    print(\"Failed to retrieve data:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert JSON files to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to convert UTC time to WIB (UTC+7)\n",
    "def convert_to_wib(utc_time_str):\n",
    "    try:\n",
    "        utc_time = datetime.strptime(utc_time_str, '%Y-%m-%dT%H:%M:%S%z')\n",
    "        wib_time = utc_time + timedelta(hours=7)  # Add 7 hours for WIB\n",
    "        return wib_time.strftime('%Y-%m-%d %H:%M:%S')  # Format to readable string\n",
    "    except Exception:\n",
    "        return utc_time_str  # Return original if not a valid datetime\n",
    "\n",
    "# Step 1: Read the JSON file\n",
    "json_file = 'facebook_page_details.json'\n",
    "with open(json_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Step 2: Normalize JSON data into a DataFrame\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "# Step 3: Convert date-time columns to WIB\n",
    "# Replace with actual column names that may contain time-related data\n",
    "date_time_columns = ['creation_date', 'created_time']  # Adjust if needed\n",
    "for col in date_time_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(convert_to_wib)\n",
    "\n",
    "# Step 4: Save the DataFrame to CSV\n",
    "csv_file = 'facebook_page_details_wib.csv'\n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"Data successfully converted and saved to '{csv_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap Post Details to JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# API Endpoint and Headers\n",
    "url = \"https://facebook-pages-scraper2.p.rapidapi.com/get_facebook_posts_details\" \n",
    "headers = {\n",
    "    \"x-rapidapi-host\": \"facebook-pages-scraper2.p.rapidapi.com\",\n",
    "    \"x-rapidapi-key\": \"YOUR_API_KEY_HERE\" # Insert API Key\n",
    "}\n",
    "\n",
    "# API Parameters (Target Facebook Page)\n",
    "params = {\"link\": \"https://www.facebook.com/YourPageName\", \"timezone\": \"UTC\"}  # Insert The Facebook Page \n",
    "\n",
    "# Make the API Request\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "# Save JSON to File\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Full JSON response\n",
    "    \n",
    "    # Save JSON data to a file\n",
    "    json_filename = \"facebook_posts.json\"\n",
    "    with open(json_filename, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)  # Pretty print JSON for readability\n",
    "    print(f\"JSON data successfully saved to '{json_filename}'\")\n",
    "else:\n",
    "    print(\"Failed to retrieve data:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert JSON files to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to convert UTC time to WIB (UTC+7)\n",
    "def convert_to_wib(utc_time_str):\n",
    "    try:\n",
    "        utc_time = datetime.strptime(utc_time_str, '%Y-%m-%dT%H:%M:%S%z')\n",
    "        wib_time = utc_time + timedelta(hours=7)  # Add 7 hours for WIB\n",
    "        return wib_time.strftime('%Y-%m-%d %H:%M:%S')  # Format to readable string\n",
    "    except Exception:\n",
    "        return utc_time_str  # Return original if not a valid datetime\n",
    "\n",
    "# Step 1: Load JSON Data\n",
    "json_filename = \"facebook_posts.json\"\n",
    "with open(json_filename, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Step 2: Extract Posts Data\n",
    "posts = data.get('data', {}).get('posts', [])\n",
    "if posts:\n",
    "    post_data = []\n",
    "    for post in posts:\n",
    "        details = post.get('details', {})\n",
    "        reactions = post.get('reactions', {})\n",
    "        values = post.get('values', {})\n",
    "        \n",
    "        # Flatten post data\n",
    "        post_data.append({\n",
    "            \"post_id\": details.get(\"post_id\"),\n",
    "            \"post_link\": details.get(\"post_link\"),\n",
    "            \"text\": values.get(\"text\"),\n",
    "            \"share_count\": details.get(\"share_count\"),\n",
    "            \"comments_count\": details.get(\"comments_count\"),\n",
    "            \"total_reaction_count\": reactions.get(\"total_reaction_count\"),\n",
    "            \"like_count\": reactions.get(\"Like\", 0),\n",
    "            \"haha_count\": reactions.get(\"Haha\", 0),\n",
    "            \"love_count\": reactions.get(\"Love\", 0),\n",
    "            \"care_count\": reactions.get(\"Care\", 0),\n",
    "            \"publish_time\": convert_to_wib(values.get(\"publish_time\", \"\")),\n",
    "            \"media_type\": values.get(\"is_media\"),\n",
    "            \"media_url\": values.get(\"photo_image\", {}).get(\"uri\", \"\")\n",
    "        })\n",
    "    \n",
    "    # Step 3: Convert to DataFrame and Save as CSV\n",
    "    df = pd.DataFrame(post_data)\n",
    "    csv_filename = \"facebook_posts_wib.csv\"\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Post data successfully converted and saved to '{csv_filename}'\")\n",
    "else:\n",
    "    print(\"No posts found in the JSON file.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
